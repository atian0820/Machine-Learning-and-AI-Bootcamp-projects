{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone: Survey Existing Research and Reproduce Available Solutions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Related Papers\n",
    "#### Source 1:\n",
    "https://www.kaggle.com/datasets/akhatova/pcb-defects\n",
    "https://www.researchgate.net/publication/332642034_TDD-Net_A_Tiny_Defect_Detection_Network_for_Printed_Circuit_Boards\n",
    "https://github.com/Ixiaohuihuihui/Tiny-Defect-Detection-for-PCB\n",
    "#### Source 2:\n",
    "https://www.kaggle.com/datasets/kubeedgeianvs/pcb-aoi\n",
    "https://ianvs.readthedocs.io/en/latest/proposals/test-reports/testing-single-task-learning-in-industrial-defect-detection-with-pcb-aoi.html\n",
    "https://github.com/kubeedge/ianvs\n",
    "\n",
    "In this execices, I will try to reproduce the result from [Source 1](https://www.kaggle.com/datasets/akhatova/pcb-defects) first, and then look into reproduce [Source 2](https://www.kaggle.com/datasets/kubeedgeianvs/pcb-aoi) as there is less reference code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source 1 Reproduction\n",
    "The PCB files can be downloaded here: https://www.kaggle.com/code/pinokiokr/pcb-defect-detection/input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET \n",
    "import ast\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as immg\n",
    "\n",
    "import random\n",
    "\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Get the current working directory\n",
    "current_path = os.getcwd()\n",
    "\n",
    "# Print the current path\n",
    "print(\"Current Path:\", current_path)\n",
    "\n",
    "images_dir = current_path + '/PCB_DATASET/images'\n",
    "annotations_dir = current_path + '/PCB_DATASET/Annotations'\n",
    "\n",
    "# Count the number of images\n",
    "# image_count = sum(len(files) for _, _, files in os.walk(images_dir))\n",
    "# print(f\"Number of images: {image_count}\")\n",
    "# annotated_image_count = sum(len(files) for _, _, files in os.walk(annotations_dir))\n",
    "# print(f\"Number of annotated images: {annotated_image_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install albumentations==0.4.6\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Generate CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "            \"xmin\":[],\n",
    "            \"ymin\":[],   \n",
    "            \"xmax\":[],\n",
    "            \"ymax\":[],\n",
    "            \"class\":[],    \n",
    "            \"file\":[],\n",
    "            \"width\":[],\n",
    "            \"height\":[],\n",
    "           }\n",
    "all_files = []\n",
    "# Files to exclude\n",
    "excluded_files = {\".DS_Store\"}\n",
    "for path, subdirs, files in os.walk(annotations_dir):\n",
    "#     print([path, subdirs, files])\n",
    "    filtered_files = [f for f in files if f not in excluded_files]\n",
    "    for name in filtered_files:\n",
    "        all_files.append(os.path.join(path, name))\n",
    "\n",
    "# print(all_files)       \n",
    "print(type(dataset))\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for anno in all_files:\n",
    "    # print(anno)\n",
    "    tree = ET.parse(anno)\n",
    "    \n",
    "    for elem in tree.iter():\n",
    "        # print(elem)\n",
    "        \n",
    "        if 'size' in elem.tag:\n",
    "            # print('[size] in elem.tag ==> list(elem)\\n'), print(list(elem))\n",
    "            for attr in list(elem):\n",
    "                if 'width' in attr.tag: \n",
    "                    width = int(round(float(attr.text)))\n",
    "                if 'height' in attr.tag:\n",
    "                    height = int(round(float(attr.text)))    \n",
    "\n",
    "        if 'object' in elem.tag:\n",
    "            # print('[object] in elem.tag ==> list(elem)\\n'), print(list(elem))\n",
    "            for attr in list(elem):\n",
    "                \n",
    "                # print('attr = %s\\n' % attr)\n",
    "                if 'name' in attr.tag:\n",
    "                    name = attr.text                 \n",
    "                    dataset['class']+=[name]\n",
    "                    dataset['width']+=[width]\n",
    "                    dataset['height']+=[height] \n",
    "                    dataset['file']+=[anno.split('/')[-1][0:-4]] \n",
    "                            \n",
    "                if 'bndbox' in attr.tag:\n",
    "                    for dim in list(attr):\n",
    "                        if 'xmin' in dim.tag:\n",
    "                            xmin = int(round(float(dim.text)))\n",
    "                            dataset['xmin']+=[xmin]\n",
    "                        if 'ymin' in dim.tag:\n",
    "                            ymin = int(round(float(dim.text)))\n",
    "                            dataset['ymin']+=[ymin]                                \n",
    "                        if 'xmax' in dim.tag:\n",
    "                            xmax = int(round(float(dim.text)))\n",
    "                            dataset['xmax']+=[xmax]                                \n",
    "                        if 'ymax' in dim.tag:\n",
    "                            ymax = int(round(float(dim.text)))\n",
    "                            dataset['ymax']+=[ymax]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(dataset)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Reading the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for testing\n",
    "train, test = train_test_split(data, shuffle=True, test_size=0.2, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_la = {\"missing_hole\": 0, \"mouse_bite\": 1, \"open_circuit\":2, \"short\": 3, 'spur': 4,'spurious_copper':5}\n",
    "\n",
    "train[\"class\"] = train[\"class\"].apply(lambda x: classes_la[x])\n",
    "test[\"class\"] = test[\"class\"].apply(lambda x: classes_la[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PJC (deep copy)\n",
    "df = train.copy()\n",
    "\n",
    "df_grp = df.groupby(['file'])\n",
    "print(df_grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrameGroupBy (https://steadiness-193.tistory.com/47)\n",
    "image_name = '01_missing_hole_02'\n",
    "image_group = df_grp.get_group(image_name)\n",
    "print(image_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = image_group.loc[:,['xmin', 'ymin', 'xmax', 'ymax']]\n",
    "print([bbox, type(bbox)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image_name, images_dir):\n",
    "    print(image_name)\n",
    "    image_group = df_grp.get_group(image_name)\n",
    "    bbox = image_group.loc[:,['xmin', 'ymin', 'xmax', 'ymax']]\n",
    "    if \"missing\" in name.split('_'):\n",
    "        images_dir += '/Missing_hole/'\n",
    "    if \"mouse\" in name.split('_'):\n",
    "        images_dir += '/Mouse_bite/'\n",
    "    if \"open\" in name.split('_'):\n",
    "        images_dir += '/Open_circuit/'\n",
    "    if \"short\" in name.split('_'):\n",
    "        images_dir += '/Short/'\n",
    "    if \"spur\" in name.split('_'):\n",
    "        images_dir += '/Spur/'\n",
    "    if \"spurious\" in name.split('_'):\n",
    "        images_dir += '/Spurious_copper/'\n",
    "   \n",
    "    img = immg.imread(images_dir+\"\"+name+'.jpg')\n",
    "    fig,ax = plt.subplots(figsize=(18,10))\n",
    "    ax.imshow(img,cmap='binary')\n",
    "    for i in range(len(bbox)):\n",
    "        box = bbox.iloc[i].values\n",
    "        print(box)\n",
    "        x,y,w,h = box[0], box[1], box[2]-box[0], box[3]-box[1]\n",
    "        rect = matplotlib.patches.Rectangle((x,y),w,h,linewidth=1,edgecolor='r',facecolor='none',)\n",
    "        # ax.text(*box[:2], image_group[\"class\"].values, verticalalignment='top', color='white', fontsize=13, weight='bold')\n",
    "        ax.add_patch(rect)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '01_missing_hole_01'\n",
    "plot_image(name, images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = train.file[500]\n",
    "plot_image(name, images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = train.file[100]\n",
    "plot_image(name, images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = train.file[105]\n",
    "plot_image(name, images_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Creating Custom database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fcbData(object):\n",
    "    def __init__(self, df, IMG_DIR, transforms): \n",
    "        self.df = df\n",
    "        self.img_dir = IMG_DIR\n",
    "        self.image_ids = self.df['file'].unique().tolist()\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        a = ''\n",
    "        if \"missing\" in image_id.split('_'):\n",
    "            a = '/Missing_hole/'\n",
    "        elif \"mouse\" in image_id.split('_'):\n",
    "            a = '/Mouse_bite/'\n",
    "        elif \"open\" in image_id.split('_'):\n",
    "            a = '/Open_circuit/'\n",
    "        elif \"short\" in image_id.split('_'):\n",
    "            a = '/Short/'\n",
    "        elif \"spur\" in image_id.split('_'):\n",
    "            a = '/Spur/'\n",
    "        elif \"spurious\" in image_id.split('_'):\n",
    "            a = '/Spurious_copper/'\n",
    "        image_values = self.df[self.df['file'] == image_id]\n",
    "        image = cv2.imread(self.img_dir+a+image_id+\".jpg\",cv2.IMREAD_COLOR)\n",
    "        print(self.img_dir+a+image_id+\".jpg\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        \n",
    "        boxes = image_values[['xmin', 'ymin', 'xmax', 'ymax']].to_numpy()\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        \n",
    "        labels = image_values[\"class\"].values\n",
    "        labels = torch.tensor(labels)\n",
    "        \n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        target['image_id'] = torch.tensor([idx])\n",
    "        target['area'] = torch.as_tensor(area, dtype=torch.float32)\n",
    "        target['iscrowd'] = torch.zeros(len(classes_la), dtype=torch.int64)\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = {\n",
    "                'image': image,\n",
    "                'bboxes': target['boxes'],\n",
    "                'labels': labels\n",
    "            }\n",
    "        \n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "            \n",
    "            target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "\n",
    "        return torch.tensor(image), target, image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform():\n",
    "    return A.Compose([\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "\n",
    "def get_valid_transform():\n",
    "    return A.Compose([\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcb_dataset   = fcbData(df, images_dir, get_train_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(fcb_dataset[0]), len(fcb_dataset[0]), type(fcb_dataset[0][0]), type(fcb_dataset[0][1]), type(fcb_dataset[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([fcb_dataset[0][0], fcb_dataset[0][1], fcb_dataset[0][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the custom dataset object created ealier works\n",
    "img, tar, _ = fcb_dataset[random.randint(0,50)]\n",
    "bbox = tar['boxes']\n",
    "fig,ax = plt.subplots(figsize=(18,10))\n",
    "ax.imshow(img.permute(1,2,0).cpu().numpy())\n",
    "for j in tar[\"labels\"].tolist():\n",
    "    classes_la = {0:\"missing_hole\", 1: \"mouse_bite\", 2:\"open_circuit\",3: \"short\", 4:'spur',5:'spurious_copper'}\n",
    "    l = classes_la[j]\n",
    "    for i in range(len(bbox)):\n",
    "        box = bbox[i]\n",
    "        x,y,w,h = box[0], box[1], box[2]-box[0], box[3]-box[1]\n",
    "        rect = matplotlib.patches.Rectangle((x,y),w,h,linewidth=2,edgecolor='r',facecolor='none',)\n",
    "        ax.text(*box[:2], l, verticalalignment='top', color='red', fontsize=13, weight='bold')\n",
    "        ax.add_patch(rect)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and test\n",
    "image_ids = df['file'].unique()\n",
    "valid_ids = image_ids[-665:]\n",
    "train_ids = image_ids[:-665]\n",
    "valid_df = df[df['file'].isin(valid_ids)]\n",
    "train_df = df[df['file'].isin(train_ids)]\n",
    "train_df.shape,valid_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V. Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = fcbData(df, images_dir, get_train_transform())\n",
    "valid_dataset = fcbData(df, images_dir, get_valid_transform())\n",
    "\n",
    "# split the dataset in train and test set\n",
    "indices = torch.randperm(len(train_dataset)).tolist()\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0, #increase worker wont work inside jupytor notebook\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "valid_data_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_data_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most pretrained models are trained with a background class, we'll include it in our model, so in that case our number of classes will be 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## num_classes = 6 # + background\n",
    "num_classes = 6\n",
    "\n",
    "# load a model; pre-trained on COCO\n",
    "# .. fpn = 'feature pyramid network'\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params, lr=0.0001, weight_decay=0.0005,)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "best_epoch = 0\n",
    "min_loss = sys.maxsize\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    tk = tqdm(train_data_loader)\n",
    "    model.train();\n",
    "    for images, targets, image_ids in tk:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        tk.set_postfix(train_loss=loss_value)\n",
    "    tk.close()\n",
    "    \n",
    "    # update the learning rate\n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch #{epoch} loss: {loss_value}\") \n",
    "        \n",
    "    #validation \n",
    "    model.eval();\n",
    "    with torch.no_grad():\n",
    "        tk = tqdm(valid_data_loader)\n",
    "        for images, targets, image_ids in tk:\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            val_output = model(images)\n",
    "            val_output = [{k: v.to(device) for k, v in t.items()} for t in val_output]\n",
    "            IOU = []\n",
    "            for j in range(len(val_output)):\n",
    "                a,b = val_output[j]['boxes'].cpu().detach(), targets[j]['boxes'].cpu().detach()\n",
    "                chk = torchvision.ops.box_iou(a,b)\n",
    "                res = np.nanmean(chk.sum(axis=1)/(chk>0).sum(axis=1))\n",
    "                IOU.append(res)\n",
    "            tk.set_postfix(IoU=np.mean(IOU))\n",
    "        tk.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample evaluation on validation dataset image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img,target,_ = valid_dataset[3]\n",
    "# put the model in evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model([img.to(device)])[0]\n",
    "    \n",
    "print('predicted #boxes: ', len(prediction['boxes']))\n",
    "print('real #boxes: ', len(target['boxes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'pcbdetection.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VII. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for i in range(50):\n",
    "    img, target, _ = valid_dataset[i]  # Load image and target\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get prediction\n",
    "        prediction = model([img.to(device)])[0]\n",
    "\n",
    "        # Ensure there is at least one label in prediction\n",
    "        if len(prediction['labels']) > 0:\n",
    "            y_true.append(target['labels'][0].item())  # Append the first label from target\n",
    "            y_pred.append(prediction['labels'][0].item())  # Append the first predicted label\n",
    "        else:\n",
    "            print(f\"No predictions for image {i}. Adding placeholder values.\")\n",
    "            y_true.append(target['labels'][0].item())  # Use the true label\n",
    "            y_pred.append(-1)  # Placeholder for no prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_pred = []\n",
    "for v in y_pred:\n",
    "    if isinstance(v, torch.Tensor):  # Check if v is a tensor\n",
    "        yy_pred.append(v.cpu().item())  # Move tensor to CPU and convert to Python scalar\n",
    "    else:\n",
    "        yy_pred.append(v)  # Append directly if v is already an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_true, yy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, yy_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
